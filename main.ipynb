{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincentjordan27/Named-Entity-Recognition-BILSTM-CRF/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zdcbTMiY9pR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import csv"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e8gd5PtmKMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2504b5dd-336e-434b-c82a-ad6ce5862971"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok6N_p_Cqav-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df86977c-1de6-48a3-f423-1168c3f731b3"
      },
      "source": [
        "!pip install torchtext==0.6.0\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.datasets import SequenceTaggingDataset\n",
        "from spacy.lang.id import Indonesian"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.62.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.10.0.2)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed sentencepiece-0.1.96 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebnOxgduZntj"
      },
      "source": [
        "maxInt = sys.maxsize\n",
        "\n",
        "while True:\n",
        "   \n",
        "    try:\n",
        "        csv.field_size_limit(maxInt)\n",
        "        break\n",
        "    except OverflowError:\n",
        "        maxInt = int(maxInt / 10)\n",
        "\n",
        "dataset = '/content/drive/My Drive/Colab Notebooks/SINGGALANG.tsv'\n",
        "data_df = pd.read_csv(dataset, sep='\\t', error_bad_lines=False, header=None, engine=\"python\", names=['word', 'tag'],\n",
        "                      quoting=csv.QUOTE_NONE)\n",
        "#print(data_df.head())\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-aVwuped655"
      },
      "source": [
        "class Corpus(object):\n",
        "\n",
        "  def __init__(self, input, min_word_freq, batch_size):\n",
        "    self.word_field = Field(lower=True)\n",
        "    self.tag_field= Field(unk_token=None)\n",
        "\n",
        "    self.train_dataset, self.val_dataset, self.test_dataset = SequenceTaggingDataset.split(\n",
        "        path=input,\n",
        "        train=\"train.tsv\",\n",
        "        validation=\"val.tsv\",\n",
        "        test=\"test.tsv\",\n",
        "        fields=((\"word\", self.word_field), (\"tag\", self.tag_field))\n",
        "    )\n",
        "\n",
        "    self.word_field.build_vocab(self.train_dataset.word, min_freg=min_word_freg)\n",
        "    self.tag_field.build_voab(self.train_dataset.tag)\n",
        "\n",
        "    self.train_iter, self.val_iter, self.test_iter = BucketIterator.splits(\n",
        "        datasets=(self.train_dataset, self.val_dataset, self.test_dataset),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    self.word_pad_idx = self.word_field.vocab.stoi[self.word_field.pad_token]\n",
        "    self.tag_pad_idx = self.tag_field.vocab.stoi[self.tag_field.pad_token]\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "p-BSG6TCqCFe",
        "outputId": "77e4ef69-3542-4023-ba9d-b07899aa3173"
      },
      "source": [
        "corpus = Corpus(\n",
        "    input=\"dataset\",\n",
        "    min_word_freq=2,\n",
        "    batch_size=60\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7a7a2f18c72f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmin_word_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-13-0ea71793673e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input, min_word_freq, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"tag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: split() got an unexpected keyword argument 'path'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "tXTM9VSuCWol",
        "outputId": "a85419b2-138f-4e97-d58a-5a2b5c1a5664"
      },
      "source": [
        "wv_shape = corpus.wv_model.wv.vectors.shape\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3f88201746e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwv_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btyPf6qTlGbU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}